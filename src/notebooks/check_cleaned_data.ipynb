{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# to make sure stopwords are correctly filtered out\n",
    "def count_remaining_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    return sum(1 for w in tokens if w in ENGLISH_STOP_WORDS)\n",
    "\n",
    "df[\"stopwords_remaining\"] = df[\"clean_text\"].apply(count_remaining_stopwords)\n",
    "\n",
    "df[\"stopwords_remaining\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d6851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make sure urls, and weird charecters filtered out\n",
    "df[\"url_count\"] = df[\"text\"].str.count(r\"http\")\n",
    "df[\"mention_count\"] = df[\"text\"].str.count(r\"@\\w+\")\n",
    "df[\"emoji_count\"] = df[\"text\"].str.count(r\"[\\U0001F600-\\U0001F64F]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 10 random samples to review \n",
    "df.sample(10)[[\"text\", \"clean_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no duplicates\n",
    "df[\"clean_text\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare length after cleaning to make sure not too much data cleaned\n",
    "df['raw_len'] = df['text'].astype(str).str.len()\n",
    "df['clean_len'] = df['clean_text'].astype(str).str.len()\n",
    "df[['raw_len', 'clean_len']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f656e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# check if data was cleaned correctly (need to fix path)\n",
    "df = clean_csv\n",
    "df[['text','clean_text']].sample(20, random_state=0)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
